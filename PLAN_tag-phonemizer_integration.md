# Plan: pygoruut & deepphoneme Language Tag Integration

## ğŸ“š **Repository & Project Context**

### **pygoruut Repository**
- **GitHub**: https://github.com/neurlang/pygoruut
- **Lizenz**: MIT License (kommerziell nutzbar)
- **Beschreibung**: Python wrapper fÃ¼r Grapheme-to-Phoneme (G2P)
- **Hugging Face Demo**: https://huggingface.co/spaces/neurlang/pygoruut

### **DeepPhonemizer Repository**
- **DeepPhonemizer**: Phoneme-to-Grapheme (P2G) Transformationen: IPA â†’ English Approximations
https://huggingface.co/spaces/roedoejet/English-Phonemes-to-Graphemes-p2g/tree/main


### **Unser TTS Pipeline Projekt**
- **Workspace**: `~/projekte/tts_pipeline_enhanced`
- **Aktuelle Pipeline**: Text â†’ Preprocessor â†’ Chunker â†’ TTS
- **Text Preprocessor**: `src/text_preprocessing/text_preprocessor.py`
- **Config System**: 3-stufige Kaskade (default_config.yaml â†’ job.yaml â†’ task.yaml)
- **Virtual Environment**: `venv/` (bereits vorhanden)

### **pygoruut Technische Details**

## ğŸ¯ **Ziel**
 G2Pâ†’P2G Transformation von Language-Tagged Text-Bereichen.

### **ğŸ¯ Warum diese Transformation:**
- **Problem**: `[lang="de"]Sindelfingen[/lang]` wÃ¼rde von TTS falsch ausgesprochen
- **LÃ¶sung**: `Zindell'fyngn` wird von englischer TTS korrekter ausgesprochen
- **Resultat**: Deutsche Ortsnamen klingen in englischer TTS natÃ¼rlich

#### **ğŸ”„ Zweistufige Transformation: OOC â†’ IPA â†’ Pseudo-British**
Das Kernkonzept ist eine **bidirektionale Phonem-Konversion** in 2 Schritten:
1. **Schritt 1 - G2P (Grapheme-to-Phoneme)**: Out-of-Context Text â†’ IPA
2. **Schritt 2 - P2G (Phoneme-to-Grapheme)**: IPA â†’ DeepPhonemizer(Pseudo-British Interpretation)

#### **Transformation Flow**
```
1. Parse Tags: [lang="de"]MÃ¼nchen[/lang] â†’ ("de", "MÃ¼nchen")
2. G2P: "MÃ¼nchen" â†’ "mËˆyËnÃ§É™n" (pygoruut)
3. IPA Fix: "mËˆyËnÃ§É™n" â†’ "mÉ¹oncen" (custom phoneme-mapping.yaml for finetuning)
4. P2G: "mÉ¹oncen" â†’ "moncen" (DeepPhonemizer)
5. Replace: "Visit moncen today!"
```

### **Sprach-Support**
- **ISO 639 Codes**: 80+ Sprachen per pygoruut (de, en, fr, es, ja, zh, etc.)
- **Non-ISO Dialekte**: EnglishBritish, EnglishAmerican, VietnameseCentral, etc.
- **VollstÃ¤ndige Liste**: Via `PygoruutLanguages().get_all_supported_languages()`

## **Installation & Dependencies**
```bash
# Virtual Environment aktivieren (IMMER ZUERST!)
source venv/bin/activate

# pygoruut installieren
pip install pygoruut

# DeepPhonemizer installieren (fÃ¼r P2G)
pip install panphon ipatok nltk
pip install git+https://github.com/roedoejet/DeepPhonemizer.git

# DeepPhonemizer Model wird automatisch in ~/.deepphoneme/ heruntergeladen

# requirements.txt erweitern
echo "pygoruut" >> requirements.txt
echo "panphon" >> requirements.txt
echo "ipatok" >> requirements.txt
echo "nltk" >> requirements.txt
echo "git+https://github.com/roedoejet/DeepPhonemizer.git" >> requirements.txt
```

### **Projektstruktur**
```
tts_pipeline_enhanced/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ default_config.yaml              # Erweiterte Config
â”‚   â””â”€â”€ [NEU] phoneme_mappings.yaml      # Sprachspezifische Mapping-Fixes
â””â”€â”€ src/
    â”œâ”€â”€ text_preprocessing/
    â”‚   â”œâ”€â”€ text_preprocessor.py         # Hauptklasse (erweitert)
    â”‚   â””â”€â”€ [NEU] language_tag_processor.py  # Neue Klasse
    
# DeepPhonemizer Model wird automatisch in ~/.deepphoneme/ verwaltet
```

## ğŸ—ï¸ **Implementierung**

### **Deliverable 1: Language Tag Processor**
- **Datei**: `src/text_preprocessing/language_tag_processor.py`
- **Klasse**: `LanguageTagProcessor`
- **Aufgabe**: Language Tags finden und transformieren

### **Deliverable 2: Text Preprocessor Integration**
- **Erweitere**: `text_preprocessor.py` 
- **Config-Option**: `process_language_tags: true`
- **Delegation**: Ruft `LanguageTagProcessor` auf

### **Wichtige Projekt-Regeln**
- **Virtual Environment**: Immer `source venv/bin/activate` vor ersten Commands
- **Code-Verfolgung**: Nach Ã„nderungen alle Referenzen proaktiv Ã¼berprÃ¼fen
- **myPy Type Checking**: PrÃ¤ventive Validierung vor Tests

## ğŸ’» **Core **

### **LanguageTagProcessor Class**
```python
import re
import unicodedata
import ipatok
import panphon.distance
import torch
from typing import List, Dict, NamedTuple
from pygoruut.pygoruut import Pygoruut
from dp.phonemizer import Phonemizer

class LanguageTag(NamedTuple):
    original: str
    language: str
    text: str

class LanguageTagProcessor:
    def __init__(self, config):
        self.pygoruut = Pygoruut(writeable_bin_dir='')
        
        # Load DeepPhonemizer model (automatically managed in ~/.deepphoneme/)
        original_load = torch.load
        torch.load = lambda *args, **kwargs: original_load(*args, **kwargs, weights_only=False)
        self.deepphoneme = Phonemizer.from_checkpoint("model_step_140k.pt")
        torch.load = original_load
        
        self.load_phoneme_mappings(config.phoneme_mappings_path)
        
        # DeepPhonemizer phone inventory (required for IPA â†’ model phone mapping)
        # Diese Phones sind vom DeepPhonemizer-Model vordefiniert und mÃ¼ssen so bleiben
        self.MODEL_PHONES = ['a', 'b', 'd', 'e', 'f', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 's', 't', 'u', 'v', 'w', 'z', 'Ã¦', 'Ã°', 'Å‹', 'É‘', 'É”', 'É™', 'É›', 'É', 'É¡', 'Éª', 'É«', 'É¹', 'Êƒ', 'ÊŠ', 'Ê’', 'Î¸']
        self.DST = panphon.distance.Distance()
    
    def find_language_tags(self, text: str) -> List[LanguageTag]:
        """Find all language tags in text"""
        pattern = r'\[lang="([^"]+)"\](.*?)\[/lang\]'
        matches = re.findall(pattern, text, re.DOTALL)
        
        tags = []
        for match in re.finditer(pattern, text, re.DOTALL):
            language, content = match.groups()
            tags.append(LanguageTag(
                original=match.group(0),
                language=language,
                text=content
            ))
        return tags
    
    def process_text(self, text: str) -> str:
        """Main processing function using optimized batch-by-language strategy"""
        # 1. Find language tags
        tags = self.find_language_tags(text)
        
        if not tags:
            return text
        
        # 2. Group tags by language (optimization from evaluation)
        language_groups = {}
        for tag in tags:
            lang = tag.language.capitalize()
            if lang not in language_groups:
                language_groups[lang] = []
            language_groups[lang].append(tag)
        
        # 3. Process each language group using batch processing
        transformations = {}
        for language, tag_group in language_groups.items():
            try:
                # Batch process all texts for this language
                texts = [tag.text for tag in tag_group]
                batch_results = self.pygoruut.phonemize_list(
                    language=language,
                    sentence_list=texts
                )
                
                # Apply custom mappings and P2G transformation
                for tag, ipa_result in zip(tag_group, batch_results):
                    ipa_text = str(ipa_result)
                    normalized_ipa = self.apply_phoneme_mappings(ipa_text, tag.language)
                    mapped_phones = self.map_phones(normalized_ipa)
                    
                    # P2G transformation
                    result = self.deepphoneme.phonemise_list([mapped_phones], lang="eng")
                    transformations[tag.original] = result.phonemes[0]
                    
            except Exception as e:
                # Fallback to individual processing for this language group
                for tag in tag_group:
                    try:
                        transformations[tag.original] = self.transform_language_tag(tag)
                    except Exception as e2:
                        print(f"Warning: Failed to process [{tag.language}]{tag.text}[/lang]: {e2}")
                        transformations[tag.original] = tag.text
        
        # 4. Replace tags in original text (maintain order)
        for tag in tags:
            if tag.original in transformations:
                text = text.replace(tag.original, transformations[tag.original])
        
        return text
    
    def transform_language_tag(self, tag: LanguageTag) -> str:
        """Transform: Text â†’ IPA â†’ English"""
        try:
            # Step 1: pygoruut G2P
            ipa_result = self.pygoruut.phonemize(
                language=self.language_mappings.get(tag.language, tag.language.capitalize()), 
                sentence=tag.text
            )
            ipa_text = str(ipa_result)
            
            # Step 2: Apply custom mappings
            normalized_ipa = self.apply_phoneme_mappings(ipa_text, tag.language)
            
            # Step 3: Map to DeepPhonemizer phone inventory
            mapped_phones = self.map_phones(normalized_ipa)
            
            # Step 4: DeepPhonemizer P2G
            result = self.deepphoneme.phonemise_list([mapped_phones], lang="eng")
            return result.phonemes[0]
            
        except Exception as e:
            # Fallback: return original text on error
            print(f"Warning: Failed to process [{tag.language}]{tag.text}[/lang]: {e}")
            return tag.text
    
    def apply_phoneme_mappings(self, ipa_text: str, language: str) -> str:
        """Apply custom phoneme mappings from YAML configuration"""
        # Unicode normalization
        normalized = unicodedata.normalize("NFC", ipa_text)
        
        # Apply global mappings (including R-Sound fixes)
        if hasattr(self, 'global_mappings'):
            for old_phone, new_phone in self.global_mappings.items():
                normalized = normalized.replace(old_phone, new_phone)
        
        # Apply language-specific mappings from YAML
        if hasattr(self, 'custom_mappings') and language in self.custom_mappings:
            for old_phone, new_phone in self.custom_mappings[language].items():
                normalized = normalized.replace(old_phone, new_phone)
        
        return normalized
    
    def map_phones(self, ipa_text: str) -> str:
        """Map IPA phones to DeepPhonemizer phone inventory"""
        phones = ipatok.tokenise(ipa_text)
        mapped = []
        
        for phone in phones:
            # Force r-sounds to English r
            if phone in ['r', 'É¾', 'Ê', 'Ê€', 'É¹']:
                mapped.append('É¹')
            else:
                distances = [self.DST.hamming_feature_edit_distance(phone, p) for p in self.MODEL_PHONES]
                best_phone = self.MODEL_PHONES[distances.index(min(distances))]
                mapped.append(best_phone)
        
        return "".join(mapped)
    
    def load_phoneme_mappings(self, mappings_path: str):
        """Load phoneme mappings and language mappings from YAML file"""
        try:
            import yaml
            with open(mappings_path, 'r') as f:
                data = yaml.safe_load(f)
                self.language_mappings = data.get('language_mappings', {})
                self.global_mappings = data.get('global_mappings', {})
                self.custom_mappings = data.get('custom_mappings', {})
        except Exception as e:
            print(f"Warning: Could not load phoneme mappings from {mappings_path}: {e}")
            # Fallback mappings
            self.language_mappings = {'de': 'German', 'en': 'English', 'fr': 'French', 'es': 'Spanish'}
            self.global_mappings = {'r': 'É¹', 'É¾': 'É¹', 'Ê': 'É¹', 'Ê€': 'É¹', 'l': 'É«', 'g': 'É¡', 'ÊŒ': 'É™'}
            self.custom_mappings = {}
```

### **Text Preprocessor Integration**
```python
class TextPreprocessor:
    def __init__(self, config):
        self.config = config
        if config.process_language_tags:
            self.language_processor = LanguageTagProcessor(config.language_tag_processor)
    
    def preprocess_text(self, text: str) -> str:
        """Main preprocessing with language tag support"""
        # Process language tags if enabled
        if self.config.process_language_tags:
            text = self.language_processor.process_text(text)
        
        # Other preprocessing...
        return text
```

# Arbeitsablauf

## ğŸ”¬ **Phase 1: Proof-of-Concept & Testing**

### **1.1 Grundlegende pygoruut Tests** âœ… ERLEDIGT
- **Ziel**: Verhalten und Ergebnisse von pygoruut evaluieren

### **1.2 Language Mapping Tests** âœ… ERLEDIGT
- **Ziel**: Testen ob pygoruuts eingebaute ISO-639 UnterstÃ¼tzung ausreicht

### **1.3 Batch Processing Evaluation** âœ… ERLEDIGT
- **Entscheidung**: **"Batch by Language"** - 64x schneller als Individual Processing bei 100% Erfolgsrate. (Siehe: test_batch_processing.py)
**Wichtige Erkenntnisse**
- pygoruut's `phonemize_list()` ist extrem effizient fÃ¼r Batch Processing
- Sprach-Gruppierung ist der SchlÃ¼ssel fÃ¼r optimale Performance
- Fallback auf Individual Processing ist robuste Fehlerbehandlung


## ğŸ—ï¸ **Phase 2: Implementierung**

### **2.1 Configuration erweitern**
```yaml
# config/default_config.yaml
text_preprocessing:
  process_language_tags: true
  language_tag_processor:
    phoneme_mappings_path: "config/phoneme_mappings.yaml"
```

### **2.2 Language Tag Processor Klasse**

- **Neue Datei**: `src/text_preprocessing/language_tag_processor.py`
- **Klasse**: `LanguageTagProcessor`
- **Nicht** in `text_preprocessor.py` integriert â†’ Separation of Concerns

### **2.3 Tag Parser & Validator**
- **Regex Pattern**: `r'\[lang="([^"]+)"\](.*?)\[/lang\]'`
- **Validierung**:
  - UnterstÃ¼tzte Sprachen via `pygoruut.get_supported_languages()`
  - Nested Tags Detection & Warnung
  - Malformed Tags Detection (and removal)

### **2.4 Core Transformation Pipeline** (âœ… **Optimiert mit Batch-by-Language**)
```python
def process_language_tagged_text(text: str, target_language: str = "en") -> str:
    """
    Input:  "Hello! [lang="de"]Sindelfingen[/lang] is beautiful."
    Output: "Hello! Zindell'fyngn is beautiful."
    """
    # 1. Parse & Validate Tags
    # 2. Group Tags by Language (OPTIMIZATION)
    # 3. Batch Transform per Language: G2P(source_lang) â†’ P2G(target_lang)
    # 4. Replace in Original Text (maintain order)
    # 5. Return Clean Text
```

### **2.5 Integration in Text Preprocessor**
- **Minimale Ã„nderung** in `text_preprocessor.py`
- **Delegation**: `if config.process_language_tags: self.language_processor.process_text(...)`
- **Instanziierung**: `self.language_processor = LanguageTagProcessor()`

### **2.6 R-Sound-Fix implementieren

- **YAML-basierte Konfiguration**: Custom Mappings to finetune often occuring mapping errors via "phoneme_mappings.yaml"-file

É¾ (deutscher Tap) â†’ É« (L-Laut) â†’ englisches "l"
Nur r â†’ É¹ funktioniert korrekt

Verbesserte Mapping-Strategie: 100% R-Erhaltung (5/5 WÃ¶rter)
Brot â†’ bÉ¹ot â†’ brot (statt blt)
grÃ¶ÃŸer â†’ gÉ¹esÉ™ â†’ gresa (statt glesa)

```yaml
# config/phoneme_mappings.yaml

# Language code mappings (ISO â†’ pygoruut names)
language_mappings:
  de: German
  en: English
  fr: French
  es: Spanish
  it: Italian
  pt: Portuguese
  nl: Dutch
  ru: Russian
  ja: Japanese
  zh: Chinese
  ga: Irish
  da: Danish

# Global phoneme mappings (applied to all languages)
global_mappings:
  # Standard IPA normalizations
  l: É«      # l â†’ velarized l
  ÊŒ: É™      # ÊŒ â†’ schwa
  g: É¡      # g â†’ voiced velar stop
  
  # R-Sound preservation (bewÃ¤hrt - applies to all languages)
  Ê: É¹      # uvular r â†’ English r
  É¾: É¹      # tap r â†’ English r
  Ê€: É¹      # trill r â†’ English r
  r: É¹      # any remaining r â†’ English r

# Language-specific custom mappings
custom_mappings:
  de:  # German
    Ê: Éª    # Ã¼-Laut â†’ i-Laut
    Ã¸: e    # Ã¶-Laut â†’ e-Laut
    Ã§: k    # ch-Laut â†’ k-Laut (optional)
  fr:  # French  
    # French-specific mappings (R-fix already global)
    Å“: e    # Å“ â†’ e
  es:  # Spanish
    # Spanish-specific mappings (R-fix already global)
    Î²: b    # Î² â†’ b
```

### **2.6.1 Mapping Validation System**
- **Schema-Validation**: Automatische ÃœberprÃ¼fung der YAML-Dateien
- **Konflikt-Erkennung**: WidersprÃ¼chliche Mappings zwischen Dateien



## ğŸ§ª **Phase 3: Testing & Validation**

### **3.1 Unit Tests**
- Tag Parsing Edge Cases
- Error Handling

### **3.2 Integration Tests**
- End-to-End Pipeline
- Chunker-Compatibility

### **3.3 User Feedback Features**
- **Detailliertes Logging in verbose-mode**:
  - Erkannte Tags
  - Transformationen
  - Fehlgeschlagene Konvertierungen
- **Validation Messages in verbose-mode**:
- **Unbekannte Sprachen**: Warnung + Original Text beibehalten
- **Malformed Tags**: Warnung + Tag entfernen
- **Nested Tags**: Warnung + Outer Tag verwenden

## ğŸ“‹ **Technische Spezifikationen**

### **Supported Tag Format**
```
[lang="LANGUAGE_CODE"]Text[/lang]
```

### **Language Codes**
- **ISO 639**: `de`, `en`, `fr`, `es`, etc.
- **Non-ISO**: `EnglishBritish`, `EnglishAmerican`, etc.
- **Validation**: Via `PygoruutLanguages().get_all_supported_languages()`

### **Performance Considerations** 
- **Batch Strategy**: âœ… **"Batch by Language"** - Evaluationsergebnis: 64x schneller als Individual Processing
- **Optimierungsstrategie**: 
  - Tags nach Sprache gruppieren
  - `pygoruut.phonemize_list()` fÃ¼r alle Texte derselben Sprache
  - Fallback auf Individual Processing bei Batch-Fehlern
- **Caching**: KISS! Verlass auf pygoruut's und deepphoneme's eingebautes Caching
- **Lazy Loading**: pygoruut erst bei Bedarf initialisieren

## ğŸ”„ **Workflow**

### **Config: `process_language_tags: true`**
```
Input Text â†’ Tag Parser â†’ Group by Language â†’ Batch pygoruut (G2P) â†’ Custom Mapping â†’ DeepPhonemizer (P2G) â†’ Clean Text â†’ Chunker
                     â†“
         [lang="de"]MÃ¼nchen[/lang] + [lang="de"]Berlin[/lang] 
                     â†“
              Batch: ["MÃ¼nchen", "Berlin"] â†’ ["mËˆyËnÃ§É™n", "bÉ›É¾lËˆiËn"]
```

### **Config: `process_language_tags: false`**
```
Input Text â†’ [Tags ignored] â†’ Clean Text â†’ Chunker
```

## ğŸ“š **Phase 4: Documentation**

### **4.1 User Guide**
- **Tag-Syntax**: Beispiele und Best Practices
- **UnterstÃ¼tzte Sprachen**: Liste aller ISO/Non-ISO Codes (Kurz erwÃ¤hen)
- **Konfiguration**: Setup und Troubleshooting (kurz)

### **4.2 Developer Documentation**
- in "TECHNICAL_OVERVIEW.md"
- **API Reference**: `LanguageTagPhonemizer` Klasse