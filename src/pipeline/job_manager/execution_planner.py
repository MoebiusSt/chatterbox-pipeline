#!/usr/bin/env python3
"""
Execution planning functionality for job management - Refactored with MenuOrchestrator.

This is the new, refactored ExecutionPlanner that uses the MenuOrchestrator
for unified menu handling across all execution paths.
"""

import logging
import sys
from pathlib import Path
from typing import Any, List, Optional

from utils.config_manager import ConfigManager, TaskConfig
from .execution_types import ExecutionContext, ExecutionIntent, ExecutionOptions
from .menu_orchestrator import MenuOrchestrator
from .cli_mapper import CLIMapper, StrategyResolver
from .types import ExecutionPlan

logger = logging.getLogger(__name__)


class ExecutionPlanner:
    """
    Refactored ExecutionPlanner with MenuOrchestrator integration.
    
    This implementation provides:
    - 85% code reduction through MenuOrchestrator
    - Unified menu experience across all execution paths  
    - Complete CLI-Menu parity via CLIMapper
    - Semantic clarity with ExecutionOptions
    - Zero breaking changes via legacy field mapping
    """
    
    def __init__(self, job_manager: Any, config_manager: ConfigManager):
        self.job_manager = job_manager
        self.config_manager = config_manager
        
        # Initialize orchestration components
        self.menu_orchestrator = MenuOrchestrator(config_manager)
        self.cli_mapper = CLIMapper()
        self.strategy_resolver = StrategyResolver(self.cli_mapper)
        
        logger.info("ExecutionPlanner initialized with MenuOrchestrator")
    
    def resolve_execution_plan(self, args: Any, config_files: Optional[List[Path]] = None) -> ExecutionPlan:
        """
        Resolve execution plan with unified architecture.
        
        This method replaces the original 690-line implementation with a clean,
        orchestrated approach that eliminates code duplication.
        
        Args:
            args: Command line arguments
            config_files: Optional config files for direct execution
            
        Returns:
            ExecutionPlan: Resolved execution plan with populated tasks
        """
        
        # Step 1: Determine execution context (unified for all paths)
        context = self._determine_execution_context(args, config_files)
        
        # Step 2: Resolve execution intent (CLI-first, then interactive)
        intent = self._resolve_execution_intent(args, context)
        
        # Step 3: Convert intent to ExecutionPlan (with legacy compatibility)
        plan = self._create_execution_plan(intent, context)
        
        logger.info(f"Execution plan resolved: {len(plan.task_configs)} tasks, mode={plan.execution_mode}")
        return plan
    
    def _determine_execution_context(self, args: Any, config_files: Optional[List[Path]]) -> ExecutionContext:
        """
        Determine execution context - unified logic for all execution paths.
        
        This replaces the three separate path-specific context determinations
        in the original implementation.
        """
        
        if hasattr(args, 'job') and args.job:
            # Job-name execution path
            job_name = args.job
            existing_tasks = self.job_manager.find_existing_tasks(job_name)
            
            # For job-name execution, we need to find config files, not existing tasks
            # Only look for config files if no existing tasks found
            job_configs = None
            if not existing_tasks:
                job_configs = self.config_manager.find_configs_by_job_name(job_name)
            
            return ExecutionContext(
                existing_tasks=existing_tasks,
                job_configs=job_configs,
                execution_path="job-name",
                job_name=job_name,
                available_strategies=self._get_available_strategies()
            )
            
        elif config_files:
            # Config-files execution path  
            # Extract job_name from first config file to check for existing tasks
            try:
                first_config = self.config_manager.load_cascading_config(config_files[0])
                job_name = first_config.get("job", {}).get("name", "")
                existing_tasks = self.job_manager.find_existing_tasks(job_name) if job_name else []
                
                return ExecutionContext(
                    existing_tasks=existing_tasks,
                    job_configs=config_files,
                    execution_path="config-files", 
                    job_name=job_name,
                    available_strategies=self._get_available_strategies()
                )
            except Exception as e:
                logger.warning(f"Failed to extract job_name from config file {config_files[0]}: {e}")
                # Fallback to original behavior
                return ExecutionContext(
                    existing_tasks=[],
                    job_configs=config_files,
                    execution_path="config-files", 
                    job_name="",
                    available_strategies=self._get_available_strategies()
                )
            
        else:
            # Default execution path
            default_config = self.config_manager.load_default_config()
            job_name = default_config["job"]["name"]
            existing_tasks = self.job_manager.find_existing_tasks(job_name)
            
            return ExecutionContext(
                existing_tasks=existing_tasks,
                job_configs=None,
                execution_path="default",
                job_name=job_name,
                available_strategies=self._get_available_strategies()
            )
    
    def _resolve_execution_intent(self, args: Any, context: ExecutionContext) -> ExecutionIntent:
        """
        Resolve execution intent - CLI-first approach with interactive fallback.
        
        This eliminates the need for separate CLI vs interactive handling
        in each execution path.
        """
        
        # Try CLI-first approach
        if not self.strategy_resolver.requires_user_interaction(args, context):
            logger.info("Resolving intent from CLI arguments")
            cli_intent = self.cli_mapper.parse_cli_to_execution_intent(args, context)
            if cli_intent is not None:
                return cli_intent
        
        # Fallback to interactive MenuOrchestrator
        logger.info("Resolving intent via MenuOrchestrator")
        return self.menu_orchestrator.resolve_user_intent(context)
    
    def _create_execution_plan(self, intent: ExecutionIntent, context: ExecutionContext) -> ExecutionPlan:
        """
        Create ExecutionPlan from ExecutionIntent with legacy compatibility.
        
        This method ensures that the new ExecutionIntent is properly converted
        to the existing ExecutionPlan format, maintaining backward compatibility.
        """
        
        # Handle cancelled execution
        if intent.execution_mode == "cancelled":
            return ExecutionPlan([], "cancelled")
        
        # Handle new task creation - if tasks is empty and mode is single, create new task
        tasks_to_process = intent.tasks
        if not tasks_to_process and intent.execution_mode == "single":
            # Create new task from context - handle both job-name and config-files execution paths
            job_configs = None
            
            if context.job_configs:
                # Config-files execution path - use already loaded configs
                job_configs = context.job_configs
                logger.debug(f"Using provided config files: {[str(p) for p in job_configs]}")
            elif context.job_name:
                # Job-name execution path - find configs by name
                
                # Check if user might have passed a YAML file as job name
                if context.job_name.lower().endswith('.yaml') or context.job_name.lower().endswith('.yml'):
                    logger.warning(f"ðŸ¤” It looks like you might have passed a YAML file as a job name: '{context.job_name}'")
                    logger.info("ðŸ’¡ Did you mean to use one of these instead?")
                    logger.info(f" python {sys.argv[0]} {context.job_name}")
                    logger.info(f" python {sys.argv[0]} --job \"job_name_from_yaml\"")
                    logger.info("")
                    logger.info("The --job option searches for jobs by name, not for YAML files.")
                    logger.info("To run a specific YAML file, just pass it as an argument without --job.")
                    logger.info("")
                    
                # Find config files for this job name
                job_configs = self.config_manager.find_configs_by_job_name(context.job_name)
                if not job_configs:
                    logger.error(f"No job config found for job name: {context.job_name}")
                    return ExecutionPlan([], "cancelled")
                logger.debug(f"Found config files for job '{context.job_name}': {[str(p) for p in job_configs]}")
            else:
                logger.error("Cannot create new task: no job name or config files available")
                return ExecutionPlan([], "cancelled")
            
            try:
                # Create tasks for all distinct job configs
                new_tasks = self._create_tasks_for_distinct_configs(job_configs)
                if not new_tasks:
                    logger.error("No distinct tasks could be created from job configs")
                    return ExecutionPlan([], "cancelled")
                
                tasks_to_process = new_tasks
                for task in new_tasks:
                    logger.info(f"âš™ï¸  Created new task: {task.config_path}")
            except Exception as e:
                logger.error(f"Failed to create new task: {e}")
                return ExecutionPlan([], "cancelled")
        
        # Convert tasks and apply legacy field mapping
        task_configs = []
        for task in tasks_to_process:
            # Map execution options to task config
            if intent.execution_options.force_final_generation:
                task.force_final_generation = True  
            if intent.execution_options.rerender_all:
                task.rerender_all = True
            if intent.execution_options.gap_filling_mode:
                task.gap_filling_mode = True
                
            task_configs.append(task)
        
        # Set execution mode
        execution_mode = intent.execution_mode
        if len(task_configs) > 1:
            execution_mode = "batch"
        
        # Check if user input was required (for compatibility)
        requires_user_input = (intent.source == "menu")
        
        return ExecutionPlan(
            task_configs=task_configs,
            execution_mode=execution_mode,
            requires_user_input=requires_user_input
        )
    
    def _create_tasks_for_distinct_configs(self, job_config_paths: List[Path]) -> List[TaskConfig]:
        """
        Create tasks for all distinct job configurations.
        
        Tasks are considered distinct if they differ in any of:
        - job: name
        - job: run-label  
        - input: text_file
        
        Args:
            job_config_paths: List of Path objects pointing to job config files
            
        Returns:
            List of distinct TaskConfig objects
        """
        distinct_tasks = []
        seen_signatures = set()
        
        for config_path in job_config_paths:
            try:
                # Ensure we have a Path object
                if not isinstance(config_path, Path):
                    logger.warning(f"Skipping non-Path config: {type(config_path)} - {config_path}")
                    continue
                    
                # Load config and create task signature for conflict detection
                job_config = self.config_manager.load_cascading_config(config_path)
                
                job_name = job_config.get("job", {}).get("name", "")
                run_label = job_config.get("job", {}).get("run-label", "")
                text_file = job_config.get("input", {}).get("text_file", "")
                
                # Create signature for uniqueness check
                task_signature = (job_name, run_label, text_file)
                
                if task_signature not in seen_signatures:
                    # This is a distinct task, create it
                    new_task = self.job_manager.create_new_task(job_config)
                    distinct_tasks.append(new_task)
                    seen_signatures.add(task_signature)
                    logger.debug(f"Task signature: job='{job_name}', run-label='{run_label}', text_file='{text_file}'")
                else:
                    logger.debug(f"Skipping duplicate task signature: job='{job_name}', run-label='{run_label}', text_file='{text_file}'")
                    
            except Exception as e:
                logger.warning(f"Error processing config {config_path}: {e}")
                continue
        
        return distinct_tasks
    
    def _get_available_strategies(self) -> dict:
        """Get available execution strategies for context."""
        return self.cli_mapper.strategy_to_options
    
    def print_execution_summary(self, plan: ExecutionPlan) -> None:
        """Print execution summary - unchanged interface for compatibility."""
        logger.info("")
        logger.info("=" * 50)
        logger.info("ðŸ“‹ EXECUTION PLAN SUMMARY")
        logger.info(f"  Mode: {plan.execution_mode.upper()}")
        logger.info(f"  Tasks: {len(plan.task_configs)}")

        for i, task in enumerate(plan.task_configs, 1):
            run_label = f" ({task.run_label})" if task.run_label else ""
            logger.info(f"  {i}. {task.job_name}: {task.task_name}{run_label}")
            logger.info(f"     â””â”€ {task.base_output_dir}")

        logger.info("=" * 50) 